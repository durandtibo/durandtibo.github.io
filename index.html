<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Thibaut Durand</title>

    <meta name="author" content="Thibaut Durand">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Thibaut Durand
                </p>
                <p>
    I'm a Staff Machine Learning Researcher at <a href="https://rbcborealis.com/">RBC Borealis</a> (formerly Borealis AI) in Vancouver, BC, Canada, where I work at the intersection of ML and finance, creating intelligent and human-centered systems that bring meaningful change to the future of banking. 
    Previously, I was a Postdoctoral Fellow in Computer Vision and Machine Learning at <a href="https://www.sfu.ca/">Simon Fraser University</a>, working under the supervision of <a href="https://www.cs.sfu.ca/~mori/">Greg Mori</a>. 
    I earned my PhD from <a href="https://www.sorbonne-universite.fr/en">Sorbonne University</a> in Paris, France, where I was advised by <a href="https://cord.isir.upmc.fr/">Matthieu Cord</a> and <a href="https://thome.isir.upmc.fr/">Nicolas Thome</a>. 
    My thesis was focused on weakly supervised learning for visual recognition and was recognized with PhD awards from <a href="http://afrif.irisa.fr/?page_id=54">AFRIF</a> and <a href="https://www.defense.gouv.fr/aid/actualites/trois-laureats-recoivent-prix-these-dga-0">DGA</a>. 
    I regularly serves as an Area Chair or reviewer at major computer vision and machine learning conferences, including CVPR, ICCV, ECCV, ICLR, NeurIPS, and ICML.
    I'm French and Swiss, and my name is pronounced <em>Tibo</em>.              

                </p>
                <p style="text-align:center">
                  <a href="mailto:durand.tibo@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/thibaut_durand_cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/thibaut_durand_bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=89lm_XIAAAAJ&hl">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/durandtibo/">GitHub</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/thibaut-durand-60568162/">LinkedIn</a>
                  
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/thibaut_durand5.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/thibaut_durand5.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research focuses on machine learning and deep learning, with a particular interest in weakly supervised learning, temporal modeling, and multimodal learning. 
                  These areas are key to building human-centred AI systems that understand the complex and dynamic nature of the real world.
                  I have a background in computer vision, but I enjoy exploring new modalities and currently work extensively with asynchronous time series, also known as event-based data.

                </p>
                <p>
                  Below are selected publications presented at top-tier conferences and journals. For the full list, please visit <a href="https://scholar.google.com/citations?user=89lm_XIAAAAJ&hl">my Google Scholar profile</a>.
                </p>
              </td>
            </tr>

        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2025_icml_last_stop.png" alt="LAST SToP" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2502.01922">
                <span class="papertitle">LAST SToP For Modeling Asynchronous Time Series</span>
              </a>
              <br>
              <a href="https://sites.google.com/view/gshubham/home">Shubham Gupta</a>,
              <strong>Thibaut Durand</strong>,
              <a href="https://www.gwtaylor.ca/">Graham Taylor</a>,
              <a href="https://www.linkedin.com/in/drlilianwong/">Lilian W. Bia≈Çokozowicz</a>
              <br>
              <em>ICML</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2502.01922">arXiv</a> /
              <a href="posters/LAST_SToP_icml_2025.pdf">poster</a>
              <p>LAST SToP is an efficient method to adapt LLMs for asynchronous time series while preserving semantic information through language.</p>
            </td>
          </tr>

          <tr></tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2021_aistats_vsa.png" alt="Variational Selective Autoencoder" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://proceedings.mlr.press/v130/gong21a.html">
                <span class="papertitle">Variational Selective Autoencoder: Learning from Partially-Observed Heterogeneous Data</span>
              </a>
              <br>
              <a href="https://www.linkedin.com/in/yu-gong-b66a23132/">Yu Gong</a>,
              <a href="https://hossein-h.github.io/">Hossein Hajimirsadeghi</a>,
              <strong>Thibaut Durand</strong>,
              <a href="https://jiaweimtr.github.io/">Jiawei He</a>,
              <a href="https://www.cs.sfu.ca/~mori/">Greg Mori</a>
              <br>
              <em>AISTATS</em>, 2021
              <br>
              <a href="https://proceedings.mlr.press/v130/gong21a/gong21a.pdf">paper</a> / 
              <a href="https://proceedings.mlr.press/v130/gong21a/gong21a-supp.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/2102.12679">arxiv</a>
              <p>Variational Selective Autoencoder is a model designed to learn from partially observed heterogeneous data by selectively encoding observed features and effectively handling missing information.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2020_cvpr_learning_user.png" alt="user representation" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Durand_Learning_User_Representations_for_Open_Vocabulary_Image_Hashtag_Prediction_CVPR_2020_paper.pdf">
                <span class="papertitle">Learning User Representations for Open Vocabulary Image Hashtag Prediction</span>
              </a>
              <br>
              <strong>Thibaut Durand</strong>
              <br>
              <em>CVPR</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Durand_Learning_User_Representations_for_Open_Vocabulary_Image_Hashtag_Prediction_CVPR_2020_paper.pdf">paper</a>
              <p>A model that learns user-conditioned representations to improve open vocabulary image hashtag prediction by capturing individual user preferences and context.</p>
            </td>
          </tr>

          <tr></tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2019_iccv_layout_vae.png" alt="Layout-VAE" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Jyothi_LayoutVAE_Stochastic_Scene_Layout_Generation_From_a_Label_Set_ICCV_2019_paper.html">
                <span class="papertitle">LayoutVAE: Stochastic Scene Layout Generation From a Label Set</span>
              </a>
              <br>
              <a href="https://ajakash.github.io/">Akash Abdu Jyothi</a>,
              <strong>Thibaut Durand</strong>,
              <a href="https://jiaweimtr.github.io/">Jiawei He</a>,
              <a href="https://www.cs.ubc.ca/~lsigal/">Leonid Sigal</a>,
              <a href="https://www.cs.sfu.ca/~mori/">Greg Mori</a>
              <br>
              <em>ICCV</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Jyothi_LayoutVAE_Stochastic_Scene_Layout_Generation_From_a_Label_Set_ICCV_2019_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Jyothi_LayoutVAE_Stochastic_Scene_ICCV_2019_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/1907.10719">arxiv</a>
              <p>LayoutVAE is a generative model that learns to produce diverse and coherent scene layouts from a given set of object labels using a variational auto-encoder framework.</p>
            </td>
          </tr>

          <tr></tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2019_cvpr_app_vae.png" alt="APP-VAE" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mehrasa_A_Variational_Auto-Encoder_Model_for_Stochastic_Point_Processes_CVPR_2019_paper.html">
                <span class="papertitle">A Variational Auto-Encoder Model for Stochastic Point Processes</span>
              </a>
              <br>
              <a href="https://nmehrasa.github.io/">Nazanin Mehrasa</a>,
              <a href="https://ajakash.github.io/">Akash Abdu Jyothi</a>,
              <strong>Thibaut Durand</strong>,
              <a href="https://jiaweimtr.github.io/">Jiawei He</a>,
              <a href="https://www.cs.ubc.ca/~lsigal/">Leonid Sigal</a>,
              <a href="https://www.cs.sfu.ca/~mori/">Greg Mori</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Mehrasa_A_Variational_Auto-Encoder_Model_for_Stochastic_Point_Processes_CVPR_2019_paper.pdf">paper</a> / 
              <a href="https://arxiv.org/abs/1904.03273">arxiv</a>
              <p>A variational auto-encoder framework for modeling stochastic point processes by learning flexible representations of temporal event data using neural networks.</p>
            </td>
          </tr>

          <tr></tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2019_cvpr_partial_labels.png" alt="partial labels" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Durand_Learning_a_Deep_ConvNet_for_Multi-Label_Classification_With_Partial_Labels_CVPR_2019_paper.html">
                <span class="papertitle">Learning a Deep ConvNet for Multi-label Classification with Partial Labels</span>
              </a>
              <br>
              <strong>Thibaut Durand</strong>,
              <a href="https://nmehrasa.github.io/">Nazanin Mehrasa</a>,
              <a href="https://www.cs.sfu.ca/~mori/">Greg Mori</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Durand_Learning_a_Deep_ConvNet_for_Multi-Label_Classification_With_Partial_Labels_CVPR_2019_paper.pdf">paper</a> /
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Durand_Learning_a_Deep_CVPR_2019_supplemental.pdf">supp</a> / 
              <a href="https://arxiv.org/abs/1902.09720">arxiv</a>
              <p>A deep ConvNet approach for multi-label classification that can learn effectively from partially labeled data by leveraging label correlations and handling label uncertainty during training.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2018_tpami_resnet-weldon_small.png" alt="Exploiting Negative Evidence" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://hal.sorbonne-universite.fr/hal-01969819/file/2018PAMIcord_sans%20marque.pdf">
                <span class="papertitle">Exploiting Negative Evidence for Deep Latent Structured Models</span>
              </a>
              <br>
              <strong>Thibaut Durand</strong>,
              <a href="https://thome.isir.upmc.fr/">Nicolas Thome</a>,
              <a href="https://cord.isir.upmc.fr/">Matthieu Cord</a>,
              <br>
              <em>TPAMI</em>, 2018
              <br>
              <a href="https://hal.sorbonne-universite.fr/hal-01969819/file/2018PAMIcord_sans%20marque.pdf">paper</a> / 
              <a href="https://github.com/durandtibo/wildcat.pytorch">code</a>
              <p>A deep latent structured model that incorporates negative evidence through a novel pooling strategy, enabling more accurate classification, ranking, and weakly supervised segmentation by explicitly penalizing incorrect class predictions.</p>
            </td>
          </tr>
            
          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2017_cvpr_wildcat_small.png" alt="WILDCAT" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Durand_WILDCAT_Weakly_Supervised_CVPR_2017_paper.html">
                <span class="papertitle">WILDCAT: Weakly Supervised Learning of Deep ConvNets for Image Classification, Pointwise Localization and Segmentation</span>
              </a>
              <br>
              <strong>Thibaut Durand</strong>,
              <a href="https://scholar.google.com/citations?user=wqBOFKEAAAAJ">Taylor Mordan</a>,
              <a href="https://thome.isir.upmc.fr/">Nicolas Thome</a>,
              <a href="https://cord.isir.upmc.fr/">Matthieu Cord</a>,
              <br>
              <em>CVPR</em>, 2017
              <br>
              <a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Durand_WILDCAT_Weakly_Supervised_CVPR_2017_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content_cvpr_2017/supplemental/Durand_WILDCAT_Weakly_Supervised_2017_CVPR_supplemental.pdf">supp</a> / 
              <a href="https://github.com/durandtibo/wildcat.pytorch">code</a>
              <p>WILDCAT is a weakly supervised ConvNet that, using only global image labels, learns multiple class-specific feature maps plus a novel min/max pooling mechanism to enable image classification, point-wise localization, and semantic segmentation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:16px;width:20%;vertical-align:middle">
              <img src="images/papers/2016_cvpr_weldon_small.png" alt="WELDON" width="160" style="border-style: none">
            </td>
            <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_cvpr_2016/html/Durand_WELDON_Weakly_Supervised_CVPR_2016_paper.html">
                <span class="papertitle">WELDON: Weakly Supervised Learning of Deep Convolutional Neural Networks</span>
              </a>
              <br>
              <strong>Thibaut Durand</strong>,
              <a href="https://thome.isir.upmc.fr/">Nicolas Thome</a>,
              <a href="https://cord.isir.upmc.fr/">Matthieu Cord</a>,
              <br>
              <em>CVPR</em>, 2016
              <br>
              <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Durand_WELDON_Weakly_Supervised_CVPR_2016_paper.pdf">paper</a> / 
              <a href="https://openaccess.thecvf.com/content_cvpr_2016/supplemental/Durand_WELDON_Weakly_Supervised_2016_CVPR_supplemental.pdf">supp</a> / 
              <a href="https://github.com/durandtibo/wildcat.pytorch">code</a>
              <p>WELDON is a weakly supervised deep learning approach that improves image classification and localization by selecting and aggregating both the most and least activated regions in convolutional feature maps using a novel pooling strategy.</p>
            </td>
          </tr>

          <tr>
          <td style="padding:16px;width:20%;vertical-align:middle">
            <img src="images/papers/2015_iccv_mantra_small.png" alt="MANTRA" width="160" style="border-style: none">
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content_iccv_2015/html/Durand_MANTRA_Minimum_Maximum_ICCV_2015_paper.html">
              <span class="papertitle">MANTRA: Minimum Maximum Latent Structural SVM for Image Classification and Ranking</span>
            </a>
            <br>
            <strong>Thibaut Durand</strong>,
            <a href="https://thome.isir.upmc.fr/">Nicolas Thome</a>,
            <a href="https://cord.isir.upmc.fr/">Matthieu Cord</a>,
            <br>
            <em>ICCV</em>, 2015
            <br>
            <a href="https://openaccess.thecvf.com/content_iccv_2015/papers/Durand_MANTRA_Minimum_Maximum_ICCV_2015_paper.pdf">paper</a> / 
            <a href="https://github.com/durandtibo/mantra-python/">code</a>
            <p>MANTRA is a latent structural SVM framework that optimizes both minimum and maximum scoring regions in images to improve weakly supervised image classification and ranking tasks.</p>
          </td>
        </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
